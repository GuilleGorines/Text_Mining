{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports previos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import networkx as nx\n",
    "\n",
    "from Bio import Medline\n",
    "from Bio import Entrez\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones necesarias:\n",
    "\n",
    "def key_from_value(dict, query):\n",
    "    for key, values in dict.items():\n",
    "        for synonym in values:\n",
    "            if query == synonym:\n",
    "                return key\n",
    "\n",
    "def back_to_value(dict, query):\n",
    "    for keys,values in dict.items():\n",
    "        for key in keys:\n",
    "            if query == key:\n",
    "                return value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database para enfermedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLAN RAW PARA ENFERMEDADES**: en Disease Ontology, hay una lista<sup>1</sup> que contiene un ID de la enfermedad, con el id, nombre de la enfermedad y sinónimos. La idea es generar un diccionario  {key: ID y values: nombres de la enfermedad} y si se encuentra en un abstract la enfermedad (es decir, el value), cambiarlo por el ID (la key)\n",
    " \n",
    " <sup>1</sup>https://github.com/DiseaseOntology/HumanDiseaseOntology/blob/main/src/ontology/HumanDO.obo\n",
    " \n",
    "*Nota*: https://raw.githubusercontent.com/DiseaseOntology/HumanDiseaseOntology/main/src/ontology/HumanDO.obo es el raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de lista de enfermedades \n",
    "\n",
    "# Se inicializa el diccionario y las variables (inicialmente vacias y false)\n",
    "disease_dict={}\n",
    "disease_key=False\n",
    "disease_name=[]\n",
    "\n",
    "# Se abre la página del texto raw, se pone todo en minúsculas y se aplica el decode\n",
    "obo=urllib.request.urlopen('https://raw.githubusercontent.com/DiseaseOntology/HumanDiseaseOntology/main/src/ontology/HumanDO.obo')\n",
    "obo=[line.lower().decode(\"utf-8\") for line in obo]\n",
    "\n",
    "# Para cada linea del texto:\n",
    "\n",
    "# Si empieza con [term] y NO hay definidos una key y value para el diccionario, se inicializan las variables.\n",
    "# Si empieza con [term] y SÍ hay definidos una key y value para el diccionario, se añaden al diccionario y se resetean\n",
    "\n",
    "# Si empieza con id, lo convierte en key (disease_key), quitando el \"id:\", el salto de línea y los espacios en blanco\n",
    "# Si empieza con name o synonym, lo añade a la lista de values (disease_name) tras eliminar los saltos de línea, el \n",
    "#     synonym, el exact [] en el caso de los synonyms, y las comillas.\n",
    "\n",
    "# Si empieza con [typedef], significa que ya no hay más terms, y que no interesa seguir parseando, con lo que se añade\n",
    "# el último key-value y se termina\n",
    "\n",
    "for line in obo:\n",
    "            \n",
    "    if line.startswith(\"[term]\"):\n",
    "        if disease_key and disease_name:\n",
    "            disease_dict[disease_key]=disease_name\n",
    "        disease_key=str()\n",
    "        disease_name=list()\n",
    "    \n",
    "    if line.startswith(\"id\"):\n",
    "        disease_key=line.strip(\"id:\").strip(\"\\n\").strip()\n",
    "\n",
    "    elif line.startswith(\"name\"):\n",
    "        disease_name.append(line.strip(\"name:\").strip(\"\\n\").strip())\n",
    "    \n",
    "    elif line.startswith(\"synonym\"):\n",
    "        disease_name.append(line.strip(\"\\n\").strip(\"synonym: \").strip( \"exact []\").replace('\"',\"\"))\n",
    "\n",
    "    elif line.startswith(\"[typedef]\"):\n",
    "        disease_dict[disease_key] = disease_name\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El diccionario de enfermedades contiene 13046 entradas.\n"
     ]
    }
   ],
   "source": [
    "print(f'El diccionario de enfermedades contiene {len(disease_dict)} entradas.')\n",
    "# El resultado es 13046 para la versión del 22 de diciembre de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database para bacterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLAN RAW PARA BACTERIAS**:  Se obtendrá una lista con el nombre científico de las bacterias, tanto con nombre genérico como epíteto específico (ojo con pasarla a  minúsculas) en un solo string. Una opción es generar un diccionario {key: Nombre científico completo pero todo junto y values: nombre científico separado y nombre abreviado}, y repetir el proceso anterior. Así, todos los nombres científicos (staphylococcus aureus, o s.aureus, hay que recordar que estará todo en minúscula) se cambiarán por el nombre sin espacios \n",
    "(staphylococcusaureus o staphylococcus_aureus, es sencillo de lograr de cualquier método) para que al tokenizar sea un solo token. \n",
    "\n",
    "He tenido que hacer una cosa un poco fea, poner en el github la lista de los taxids de bacterias (solamente de bacterias, obtenidos a través de un grep del categories.dmp del ftp del NCBI)\n",
    "\n",
    "Tarda mucho, quizás sería buena idea guardarlo en un archivo JSON?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.max_tries=5\n",
    "Entrez.email=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de especies bacterianas encontradas es 461159.\n"
     ]
    }
   ],
   "source": [
    "bact_dict={}\n",
    "\n",
    "dmp = urllib.request.urlopen(\"https://raw.githubusercontent.com/GuilleGorines/data/main/b_categories.dmp\")\n",
    "dmp = [line.decode(\"utf-8\").strip(\"\\n\").split(\"\\t\")[1] for line in dmp]\n",
    "dmp = set(dmp)\n",
    "\n",
    "print(f'La cantidad de especies bacterianas encontradas es {len(dmp)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bacteroidales bacterium uba1745\n",
      "{'TaxId': '185291', 'ScientificName': 'unclassified Bacteroidales', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "lachnospiraceae bacterium uba7481\n",
      "{'TaxId': '186928', 'ScientificName': 'unclassified Lachnospiraceae', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "pantoea sp. a-su-d-2-7\n",
      "{'TaxId': '2630326', 'ScientificName': 'unclassified Pantoea', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "microbacterium sp. mdrc-57\n",
      "{'TaxId': '2609290', 'ScientificName': 'unclassified Microbacterium', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "bacillus sp. hpcaqrksm61\n",
      "{'TaxId': '185979', 'ScientificName': 'unclassified Bacillus', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "alpha proteobacterium tdb-125\n",
      "{'TaxId': '33807', 'ScientificName': 'unclassified Alphaproteobacteria', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "flavonifractor sp. an9\n",
      "{'TaxId': '2629267', 'ScientificName': 'unclassified Flavonifractor', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "rhizobium sp. eecc-221\n",
      "{'TaxId': '2613769', 'ScientificName': 'unclassified Rhizobium', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "alpha proteobacterium jnvu tp1\n",
      "{'TaxId': '33807', 'ScientificName': 'unclassified Alphaproteobacteria', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "streptomyces sp. ws023\n",
      "{'TaxId': '2593676', 'ScientificName': 'unclassified Streptomyces', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "burkholderia sp. 2b2\n",
      "{'TaxId': '2613784', 'ScientificName': 'unclassified Burkholderia', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "klebsiella sp. tmt3-40\n",
      "{'TaxId': '2608929', 'ScientificName': 'unclassified Klebsiella', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "rhizobium sp. saais\n",
      "{'TaxId': '2613769', 'ScientificName': 'unclassified Rhizobium', 'Rank': 'no rank'}\n",
      "\n",
      "\n",
      "mycobacterium sp. dwmj-2039a2\n",
      "{'TaxId': '2642494', 'ScientificName': 'unclassified Mycobacterium', 'Rank': 'no rank'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num,organism in enumerate(dmp):\n",
    "    search = Entrez.efetch(db='taxonomy',id=organism)\n",
    "    result = Entrez.read(search)\n",
    "    result = dict(result[0])\n",
    "    \n",
    "    print(result[\"ScientificName\"].lower())\n",
    "    print(result[\"LineageEx\"][-1])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación del corpora con Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establecen términos de búsqueda\n",
    "\n",
    "term = \"digimon\"\n",
    "\n",
    "Entrez.max_tries=5\n",
    "Entrez.email=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda inicial para comprobar cantidad de coincidencias\n",
    "\n",
    "scout_search = Entrez.esearch(db=\"pubmed\", rettype=\"count\", term = term)\n",
    "scout_result = Entrez.read(scout_search)\n",
    "id_quantity = int(scout_result[\"Count\"])\n",
    "print(f\"{id_quantity} artículo(s) encontrados en PubMed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rondas de esearch dividido en rondas de longitud máxima (100k búsquedas)\n",
    "if id_quantity > 100000:\n",
    "    rounds = int(id_quantity/100000)+1\n",
    "    retmax=100*1000\n",
    "else:\n",
    "    rounds = 1\n",
    "    retmax = id_quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa la lista de abstracts \n",
    "retstart=0\n",
    "abstracts=[]\n",
    "\n",
    "# eFetch y adición de los resultados a la lista de abstracts. \n",
    "for round in range(0,rounds):\n",
    "    \n",
    "    search = Entrez.esearch(db=\"pubmed\", retmax=retmax, term=term)\n",
    "    \n",
    "    id_quantity -= retmax\n",
    "    retstart += retmax\n",
    "    if id_quantity < 100000:\n",
    "        retmax = id_quantity\n",
    "    result = Entrez.read(search)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for single_id in result['IdList']:\n",
    "    search = Entrez.efetch(db=\"pubmed\", id=single_id, rettype=\"medline\", retmode=\"text\")\n",
    "    record = list(Medline.parse(search))\n",
    "    record = dict(record[0])\n",
    "    try:\n",
    "        record = record[\"AB\"]\n",
    "        abstracts.append(record)\n",
    "    except KeyError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_inicial=len(abstracts)\n",
    "\n",
    "print(f'La cantidad inicial de abstracts es {cantidad_inicial}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sustitución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bact_list = [bacteria for sublist in bact_dict.values() for bacteria in sublist]\n",
    "disease_list = [disease for sublist in disease_dict.values() for disease in sublist]\n",
    "\n",
    "bacterias_detectadas = []\n",
    "enfermedades_detectadas = []\n",
    "\n",
    "coincidencias = []\n",
    "\n",
    "for num,text in enumerate(abstracts):\n",
    "    bact_in_text = [num]\n",
    "    enf_in_text = [num]\n",
    "    \n",
    "    for bact in bact_list:\n",
    "        if bact in text:\n",
    "            taxid = key_from_value(bact_dict, bact)\n",
    "            text.replace(bact,taxid)\n",
    "            bact_in_text.append(taxid)\n",
    "    \n",
    "    for disease in disease_list:\n",
    "        if disease in text:\n",
    "            doid = key_from_value(disease_dict, disease)\n",
    "            text.replace(disease, doid)\n",
    "            enf_in_text.append(doid)\n",
    "    \n",
    "    bacterias_detectadas.append(bact_in_text)\n",
    "    enfermedades_detectadas.append(enf_in_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
